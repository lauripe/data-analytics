{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 4 - part 2\n",
    "Lauri Pessi | bft860\n",
    "\n",
    "## Dataset: KidCreative.xlsx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math\n",
    "from collections import namedtuple\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay, classification_report "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Obs No.</th>\n",
       "      <th>Buy</th>\n",
       "      <th>Income</th>\n",
       "      <th>Is Female</th>\n",
       "      <th>Is Married</th>\n",
       "      <th>Has College</th>\n",
       "      <th>Is Professional</th>\n",
       "      <th>Is Retired</th>\n",
       "      <th>Unemployed</th>\n",
       "      <th>Residence Length</th>\n",
       "      <th>Dual Income</th>\n",
       "      <th>Minors</th>\n",
       "      <th>Own</th>\n",
       "      <th>House</th>\n",
       "      <th>White</th>\n",
       "      <th>English</th>\n",
       "      <th>Prev Child Mag</th>\n",
       "      <th>Prev Parent Mag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>24000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>75000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>46000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>70000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>43000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Obs No.  Buy  Income  Is Female  Is Married  Has College  Is Professional  \\\n",
       "0        1    0   24000          1           0            1                1   \n",
       "1        2    1   75000          1           1            1                1   \n",
       "2        3    0   46000          1           1            0                0   \n",
       "3        4    1   70000          0           1            0                1   \n",
       "4        5    0   43000          1           0            0                0   \n",
       "\n",
       "   Is Retired  Unemployed  Residence Length  Dual Income  Minors  Own  House  \\\n",
       "0           0           0                26            0       0    0      1   \n",
       "1           0           0                15            1       0    1      1   \n",
       "2           0           0                36            1       1    1      1   \n",
       "3           0           0                55            0       0    1      1   \n",
       "4           0           0                27            0       0    0      0   \n",
       "\n",
       "   White  English  Prev Child Mag  Prev Parent Mag  \n",
       "0      0        0               0                0  \n",
       "1      1        1               1                0  \n",
       "2      1        1               0                0  \n",
       "3      1        1               1                0  \n",
       "4      1        1               0                1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get data and take a peek\n",
    "df = pd.read_excel('http://myy.haaga-helia.fi/~menetelmat/Data-analytiikka/Teaching/KidCreative.xlsx')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the data\n",
    "Let's split the data first into features X and labels y\n",
    "And then split those into separate datasets for training and testing\n",
    "- Without splitting the model would be fitter over the very same data it's going to be tested against\n",
    "    - This would make the forecasting quite boring, as you've already shown all of the correct answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign label vector y and features matrix X\n",
    "y = df['Buy']\n",
    "X = df.drop(['Obs No.', 'Buy'], axis = 1)\n",
    "\n",
    "# Split the data to training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tooling\n",
    "To embrace good conventions coming out of laziness, let's define some functions to avoid writing the same repeatedly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function for extracting precision/recall from confusion-matrix\n",
    "def precisionRecall(cm):\n",
    "    tn, fp = cm[0]\n",
    "    fn, tp = cm[1]\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    f1 = precision * recall / (precision + recall) * 2\n",
    "\n",
    "    pr = namedtuple('pr', ['Precision', 'Recall', 'F1'])\n",
    "    return pr(precision, recall, f1)\n",
    "\n",
    "\n",
    "# A generic function for fitting and scoring the models\n",
    "def scoreModel(model):\n",
    "\n",
    "    # Fit the given model using the training set and then apply to testing set\n",
    "    model.fit(X_train, y_train)\n",
    "    y_model = model.predict(X_test)\n",
    "\n",
    "    # Assign scores for return values\n",
    "    modelName = type(model).__name__\n",
    "    acc = accuracy_score(y_test, y_model)\n",
    "    cm = confusion_matrix(y_test, y_model)\n",
    "    pr = precisionRecall(cm)\n",
    "    \n",
    "    scores = namedtuple('scores', ['Model', 'Accuracy', 'Precision', 'Recall', 'F1'])\n",
    "\n",
    "    return scores(modelName, acc, pr.Precision, pr.Recall, pr.F1)\n",
    "\n",
    "\n",
    "# And another function to loop the given models through test-function and collecting the results\n",
    "def tryModels(models):\n",
    "    rs = []\n",
    "    for i in models:\n",
    "        classRef = globals()[i]\n",
    "        model = classRef()\n",
    "        rs.append(scoreModel(model))\n",
    "\n",
    "    rs = pd.DataFrame(rs).set_index('Model')\n",
    "\n",
    "    # Sort the data based on accuracy prior return\n",
    "    rs = rs.sort_values('Accuracy', ascending=False)\n",
    "    return rs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model comparison\n",
    "With the function(s) defined earlier, we can now easily run a bunch of classification models through it and see how the fare against each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the models to be tried\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GradientBoostingClassifier</th>\n",
       "      <td>0.928994</td>\n",
       "      <td>0.781250</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.806452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.757576</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.793651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GaussianNB</th>\n",
       "      <td>0.917160</td>\n",
       "      <td>0.710526</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.794118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <td>0.917160</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.774194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.721893</td>\n",
       "      <td>0.292683</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.338028</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Accuracy  Precision    Recall        F1\n",
       "Model                                                              \n",
       "GradientBoostingClassifier  0.928994   0.781250  0.833333  0.806452\n",
       "RandomForestClassifier      0.923077   0.757576  0.833333  0.793651\n",
       "GaussianNB                  0.917160   0.710526  0.900000  0.794118\n",
       "DecisionTreeClassifier      0.917160   0.750000  0.800000  0.774194\n",
       "LogisticRegression          0.721893   0.292683  0.400000  0.338028"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run the models trough \"test suite\"\n",
    "models = ['LogisticRegression', 'GaussianNB', 'DecisionTreeClassifier', 'RandomForestClassifier', 'GradientBoostingClassifier']\n",
    "tryModels(models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "Based on accuracy scoring the ensemble methods worked the best.\n",
    "- Multiple runs with different assignment of training and test data makes random forest and gradient boosting switch positions\n",
    "Classic logistic regression didn't fare well at all.\n",
    "- While accuracy was decent 72%, precision of 0.29 tells it labeled a lot of cases falsely as buy even though they weren't\n",
    "- Also recall (or sensitivity) tells that in addition to labeling many false positives, it also failed to identify many of the actual buyers\n",
    "\n",
    "Interestingly enough, GaussianNB got the highest recall of all the models while ending up at 3rd by other metrics.\n",
    "- This metric by itself is not enough, as model can get perfect recall-score by simply classifying everything as true\n",
    "- Emphasis between Precision and Recall/Sensitivity is a balancing act, you cannot get both (unless the model is flawless)\n",
    "    - In case of identifying potential buyers, the emphasis could be driven by e.g. the cost of converting the prospects to buyers\n",
    "        - If the conversion cost is low, it's better to \"shoot the barns door\" with a model having higher recall\n",
    "        - If the cost is high and you want to mimimize false positives, then Precision is the score to optimize\n",
    "        - F1-score is a combination of these two, and simplifies comparisons by offering a single metric\n",
    "\n",
    "\n",
    "## One more try\n",
    "Let's see if logistic regression could perform better, if we normalize the continuous variables closer to the 0/1 values used in booleans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.934911</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.819672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoostingClassifier</th>\n",
       "      <td>0.928994</td>\n",
       "      <td>0.781250</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.806452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.757576</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.793651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <td>0.911243</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.761905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GaussianNB</th>\n",
       "      <td>0.887574</td>\n",
       "      <td>0.622222</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.746667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Accuracy  Precision    Recall        F1\n",
       "Model                                                              \n",
       "LogisticRegression          0.934911   0.806452  0.833333  0.819672\n",
       "GradientBoostingClassifier  0.928994   0.781250  0.833333  0.806452\n",
       "RandomForestClassifier      0.923077   0.757576  0.833333  0.793651\n",
       "DecisionTreeClassifier      0.911243   0.727273  0.800000  0.761905\n",
       "GaussianNB                  0.887574   0.622222  0.933333  0.746667"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalize the two continuous variables\n",
    "X['Income'] = (X['Income'] - X['Income'].mean()) / X['Income'].std()\n",
    "X['Residence Length'] = (X['Residence Length'] - X['Residence Length'].mean()) / X['Residence Length'].std()\n",
    "\n",
    "# Split the data to training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 5)\n",
    "\n",
    "# Run same test pattern against the normalized datasets\n",
    "tryModels(models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Wow!!__\n",
    "\n",
    "## Final thoughts\n",
    "- Performance of logistic regression seems to be really sensitive to whether the variables are within similar range of values\n",
    "    - With non-normalized data the results of logistic regression were quite unsatisfactory\n",
    "    - After normalizing the two offset variables, logistic regression managed to beat also the fancy ensemble models.\n",
    "\n",
    "- What's was left missing out this \"test suite\" is averaging the results of multiple runs with randomly assigned datasets\n",
    "    - Likely this wouldn't make much difference in the big picture, but maybe the ensemble methods could have been sorted out\n",
    "        - Now with normalized dataset, I'd give a shared 2nd place for gradient boosting and random forest.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a6a10356799dbe85214c47af604556baa756ab456f4b01754adcc5fbb8ddef3a"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 ('lauri-sandbox')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
